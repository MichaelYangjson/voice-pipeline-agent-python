import logging

from dotenv import load_dotenv
from livekit.agents import (
    AutoSubscribe,
    JobContext,
    JobProcess,
    WorkerOptions,
    cli,
    llm,
)
from livekit.agents.pipeline import VoicePipelineAgent
from livekit.plugins import silero, deepgram, anthropic, openai

load_dotenv(dotenv_path=".env.local")
logger = logging.getLogger("voice-agent")


def prewarm(proc: JobProcess):
    proc.userdata["vad"] = silero.VAD.load()


from livekit.plugins.cartesia import tts

cartesia_tts = tts.TTS(
    model="sonic-english",
    voice="694f9389-aac1-45b6-b726-9d9369183238",
    speed="slow",
    emotion=["curiosity:highest", "positivity:high"]
)


async def entrypoint(ctx: JobContext):
    initial_ctx = llm.ChatContext().append(
        role="system",
        text=(
            "xml\n<instructions>\nYou are an AI partner of a 5-8 year old child named Roen, And Your name is Ainia. Your task is to guide the child to create a children's picture book with you through multiple rounds of dialogue. In this process, you need to ensure that children can learn social skills, scientific knowledge, and improve their emotional intelligence and intelligence.\nLet's complete step by step:\n1. Start the conversation:Upon receiving the start command, introduce yourself and greet the children in a friendly manner, asking if they are ready to start creating an interesting story.\n2. Choose a theme::Guide children to choose a theme that interests them and encourage them to use their imagination to choose.\n3. Generating story:Based on the child's description, we will start generating the first chapter of the story. We can imitate the ideas or plot of current children's picture books, but we cannot copy them. The chapters should be short and easy to understand, and we will ask the child if they like them\n4. Get Story feedback:If the children like it, we will continue to generate next chapter of the story based on the previous context,generate only one chapter at a time. If they don't like it, we will rewrite this chapter\n5. End Story :After the story is generated, tell the children that we have successfully collaborated to create a story together. Summarize the content of the story, learn what knowledge can, and encourage the children to create a story together next time.Finally, end the process and wait for the next one to start\n</instructions>\n\n<require>\n1. Ensure that the output does not contain any XML tags.\n2. Ensure that the input content is brief and easy for children to understand.\n3. Ensure that the tone is friendly.\n4. Ensure that the generated content should preferably include some small knowledge suitable for children, such as daily life tips\n5. Ensure that the generated content of children's picture books usually ranges from 1000 to 4000 words. If you determine that the content exceeds the word limit, you can enter the End Story process\n6. Do not copy the content of the examples. The story theme is not only about animals, space exploration, or magical worlds, but can be generated by yourself\n7. The generated content should be distinguished from regular voiceovers\n</require>\n\n<examples>\n<example>\n<user_input>start</user_input>\nHi Cute Roen, my name is Ainia. Let's create a story together,How about animals, space exploration, or a magical world?.Which one do you think is more interesting?</ user_output>\n</example>\n\n<example>\nI don't know\n<user_output>It's okay! We can think about it together. Do you like animals? Do you still prefer exploration, magic, or space travel? Or we can create a story about friendship! Which one do you think sounds interesting? Or do you not know? I can give you some inspiration.</user_output>\n</example>"),
    )

    logger.info(f"connecting to room {ctx.room.name}")
    await ctx.connect(auto_subscribe=AutoSubscribe.AUDIO_ONLY)

    # Wait for the first participant to connect
    participant = await ctx.wait_for_participant()
    logger.info(f"starting voice assistant for participant {participant.identity}")

    # This project is configured to use Deepgram STT, OpenAI LLM and TTS plugins
    # Other great providers exist like Cartesia and ElevenLabs
    # Learn more and pick the best one for your app:
    # https://docs.livekit.io/agents/plugins
    agent = VoicePipelineAgent(
        vad=ctx.proc.userdata["vad"],
        stt=deepgram.STT(),
        llm=openai.LLM(model="gpt-4o-mini", base_url="https://api.zhizengzeng.com/v1"),
        tts=cartesia_tts,
        chat_ctx=initial_ctx,
        allow_interruptions=True,

    )

    agent.start(ctx.room, participant)

    # The agent should be polite and greet the user when it joins :)
    await agent.say("Hey, what's your name", allow_interruptions=True)


if __name__ == "__main__":
    cli.run_app(
        WorkerOptions(
            entrypoint_fnc=entrypoint,
            prewarm_fnc=prewarm,
        ),
    )
